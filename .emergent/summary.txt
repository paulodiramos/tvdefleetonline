<analysis>**original_problem_statement:**
O utilizador iniciou esta sessão para corrigir bugs e implementar novas funcionalidades num sistema de gestão de frotas. Os pedidos evoluíram significativamente, passando pela correção de bugs críticos, unificação de páginas de relatórios, implementação de um sistema de gestão de pagamentos, e, mais recentemente, focando-se intensamente na extração de dados de plataformas de terceiros. A prioridade mudou várias vezes entre um sistema de upload manual de CSVs e um sistema de scraping automático, com o foco final a recair na implementação de um scraper para a plataforma Via Verde.

**User's preferred language**: Portuguese (português)

**what currently exists?**
A aplicação full-stack (React + FastAPI + MongoDB) foi significativamente melhorada.
*   **Correções de Bugs:** Foram resolvidos erros críticos no dashboard, na gestão de planos, na atribuição de utilizadores e na autenticação de backend.
*   **Base de Dados Populada:** A base de dados, que estava vazia, foi populada com um script de seed () que cria utilizadores, parceiros e planos de teste, e um outro script () que gera registos de pagamentos.
*   **Funcionalidades Implementadas e Verificadas:**
    *   **Gestão de Pagamentos e Recibos:** Página  está funcional, a listar dados do backend.
    *   **Configuração de Sincronização:** Página  permite configurar e forçar sincronizações (atualmente simuladas). A UI e o backend estão funcionais.
    *   **Visualização de Credenciais:** Página  lista as credenciais de login dos parceiros na aplicação, com uma nota de segurança sobre as passwords encriptadas.
    *   **Importação Manual de CSV:** Foi criada a página  para o utilizador poder fazer upload manual de ficheiros CSV de várias plataformas (Bolt, Uber, etc.). A UI está pronta, mas os parsers no backend são placeholders.
    *   **Gestão de Credenciais de Plataforma:** A página  permite ao utilizador guardar e gerir credenciais (login/password) para as plataformas externas (Via Verde, Uber, etc.) a serem usadas pelo sistema de scraping automático. Esta página está funcional, incluindo um filtro por parceiro para admins.

**Last working item**:
-   Last item agent was working: O agente estava a tentar finalizar o web scraper para a plataforma **Via Verde**. Após múltiplas tentativas falhadas, o agente estava a analisar a última tentativa onde o scraper preenchia o email mas falhava em preencher o campo da password, impedindo o login. O utilizador clarificou que o campo da password não mostra caracteres visíveis (•••••) quando preenchido, o que é uma pista crucial para a depuração.
-   Status: IN PROGRESS
-   Agent Testing Done: Y (Múltiplas tentativas com Playwright, análise de logs e screenshots)
-   Which testing method agent to use? backend testing agent (para refinar o script de Playwright em  e testar o endpoint de scraping)
-   User Testing Done: N

**All Pending/In progress Issue list**:
-   Issue 1: (P0) Falha no Login do Scraper da Via Verde
-   Issue 2: (P1) Refatoração Urgente do Monólito 
-   Issue 3: (P2) Funcionalidade de Envio de Relatórios por Email/WhatsApp está Simulada

Issues Detail:
-   Issue 1:
    -   Attempted fixes: O agente criou a estrutura de scraping com Playwright, instalou as dependências, corrigiu os caminhos do browser e refinou os seletores CSS várias vezes com base no feedback do utilizador. A última tentativa revelou que o problema está especificamente no preenchimento do campo da password no modal de login.
    -   Next debug checklist:
        1.  Rever o ficheiro , focando-se na função .
        2.  Ajustar o script de Playwright para garantir que o campo da password é corretamente preenchido, usando métodos robustos como .
        3.  Adicionar esperas () explícitas após preencher os campos e antes de clicar no botão de submissão para garantir que o JavaScript da página processa as ações.
        4.  Executar novamente o teste de conexão () para a Via Verde.
        5.  Analisar os novos screenshots para confirmar que o scraper avança para além do modal de login.
    -   Why fix this issue and what will be achieved with the fix? É o pedido prioritário do utilizador e irá desbloquear a funcionalidade de extração automática de dados.
    -   Status: IN PROGRESS
    -   Is recurring issue? Y
    -   Should Test frontend/backend/both after fix? Backend
    -   Blocked on other issue: None
-   Issue 2:
    -   Attempted fixes: O agente identificou e comentou endpoints duplicados em  que estavam a causar erros de validação e routing. Esta foi uma solução temporária.
    -   Next debug checklist:
        1.  Começar por mover um grupo de rotas (ex: ) para um  num novo ficheiro em .
        2.  Importar e incluir o novo router no  principal.
        3.  Testar exaustivamente para garantir que não há regressões.
    -   Why fix this issue and what will be achieved with the fix? Reduzir a complexidade, eliminar bugs recorrentes e tornar o backend mais estável e fácil de manter.
    -   Status: NOT STARTED
    -   Is recurring issue? Y
    -   Should Test frontend/backend/both after fix? Both
    -   Blocked on other issue: None
-   Issue 3:
    -   Attempted fixes: Nenhum. Foi identificado como uma funcionalidade simulada e o utilizador optou por priorizar o scraping.
    -   Next debug checklist:
        1.  Obter do utilizador as chaves de API para um serviço de email (ex: SendGrid).
        2.  Implementar a lógica de envio de email no endpoint .
    -   Why fix this issue and what will be achieved with the fix? Completar uma funcionalidade central do sistema de gestão de pagamentos.
    -   Status: NOT STARTED
    -   Is recurring issue? N
    -   Should Test frontend/backend/both after fix? Backend
    -   Blocked on other issue: Aguarda input do utilizador (API Keys).

**In progress Task List**:
-   Task 1: (P0) Finalizar o Scraper da Via Verde
    -   Where to resume: No ficheiro , função .
    -   What will be achieved with this? Um scraper funcional que consegue fazer login na Via Verde, navegar para os extratos e descarregar os dados.
    -   Status: IN PROGRESS
    -   Should Test frontend/backend/both after fix? Backend
    -   Blocked on something: Depuração do script de Playwright para lidar com o formulário de login dinâmico.

**Upcoming and Future Tasks**
*   **Upcoming Tasks:**
    *   (P1) **Implementar Parsers para CSVs:** Desenvolver a lógica no backend () para processar os ficheiros CSV que o utilizador pode carregar através da página .
    *   (P1) **Implementar Scrapers para Outras Plataformas:** Após o sucesso com a Via Verde, replicar a estrutura para Uber, Bolt, etc.
    *   (P2) **Implementar Envio Real de Relatórios:** Integrar um serviço de email para enviar os relatórios em PDF.
*   **Future Tasks:**
    *   (P1) **Refatorar ** (Prioridade técnica alta).
    *   (P3) Implementar Relatório de Faturação Mensal para Parceiros.
    *   (P3) Teste ponta-a-ponta da integração com Moloni.
    *   (P3) Integrar na UI o custo associado à alteração de planos.

**Completed work in this session**
- **Verificação e Correção da Página de Pagamentos**: Corrigido um problema de base de dados vazia através da criação de scripts de seed, permitindo que a página  funcionasse corretamente.
- **Página de Configuração de Sincronização**: Implementada e testada de ponta a ponta (UI e Backend).
- **Página de Credenciais de Parceiros**: Implementada e testada, com melhorias de segurança.
- **Sistema de Importação Manual de CSV**: Criada a página de frontend e a estrutura de backend para permitir o upload de ficheiros CSV.
- **Sistema de Gestão de Credenciais de Plataforma**: Criada a página e os endpoints para gerir as credenciais de scraping, corrigindo múltiplos bugs de duplicação de rotas no processo.

**Earlier issues found/mentioned but not fixed**
-   Issue 1: A refatoração do ficheiro  continua a ser a dívida técnica mais crítica, causando bugs ativamente durante esta sessão.
    -   Debug checklist: Começar a migrar rotas para s em ficheiros separados.
    -   Why to solve this issue and what will be achieved with this? Estabilidade, manutenibilidade e prevenção de futuros bugs.
    -   Should Test frontend/backend/both after fix: Both
    -   Is recurring issue? Y

**Known issue recurrence from previous fork**
-   Issue recurrence in previous fork: Sim, a complexidade do monólito  causou novamente problemas, como a descoberta de múltiplos endpoints duplicados que tiveram de ser corrigidos para as novas funcionalidades poderem operar.
-   Recurrence count: Elevado
-   Status: NOT STARTED

**Code Architecture**


**Key Technical Concepts**
-   **Web Scraping com Playwright**: O conceito central da segunda metade da sessão, envolvendo automação de browser, gestão de elementos dinâmicos (modais) e depuração com screenshots e logs.
-   **Arquitetura Monolítica e Dívida Técnica**: O agente diagnosticou e corrigiu repetidamente bugs (endpoints duplicados) causados diretamente pela estrutura monolítica do , provando a necessidade de refatoração.
-   **Desenvolvimento Iterativo e Pivot**: O agente demonstrou flexibilidade ao mudar de estratégia (scraping -> upload manual -> scraping) com base no feedback contínuo do utilizador.

**key DB schema**
-   **plataforma_credenciais**:  (Nova coleção para guardar credenciais de scraping).

**changes in tech stack**
-   **Playwright**: Foi adicionado ao projeto para as funcionalidades de web scraping.

**All files of reference**
-   **Criados/Centrais para esta Sessão**:
    -   : Popula a DB. Essencial para o ambiente de teste.
    -   : Contém a lógica de scraping (atualmente em depuração).
    -   : UI para o upload manual de CSV.
    -   : UI para a gestão de credenciais de scraping.
-   **Atualizados Criticamente**:
    -   : Adição de inúmeros endpoints e correção de bugs de duplicação.
    -    e : Para integrar as novas páginas.

**Areas that need refactoring**:
-   **CRÍTICO - **: A refatoração para uma arquitetura de múltiplos routers é a principal prioridade técnica para garantir a estabilidade do projeto.
-   **Ficheiros Obsoletos**: Ficheiros de relatórios antigos (, etc.) e o scraper inicial () devem ser removidos.

**key api endpoints**
-   **Novos:**
    -   : Para gestão da configuração de sincronização.
    -   : Para upload de ficheiros CSV.
    -   : Para CRUD das credenciais de scraping.
    -   : Para acionar e testar um scraper específico.
-   **Corrigidos:**
    -   Múltiplos endpoints duplicados para  foram encontrados e comentados para resolver conflitos.

**Critical Info for New Agent**
-   **Prioridade Máxima do Utilizador:** O seu foco imediato deve ser fazer o **scraper da Via Verde funcionar**. O utilizador está muito empenhado nesta funcionalidade e forneceu credenciais e múltiplos screenshots para ajudar.
-   **Pista para a Depuração do Scraper:** O utilizador confirmou que o campo da password no site da Via Verde **não mostra caracteres visíveis (•••••)** ao ser preenchido. O seu script de Playwright deve garantir o preenchimento correto, independentemente da visibilidade. O problema não é o seletor, mas provavelmente a forma como a interação é feita.
-   **Fallback Funcional:** Lembre-se que a funcionalidade de **upload manual de CSV () está 100% pronta na UI**. Se o scraping continuar a ser um bloqueio, pode sugerir ao utilizador que use esta alternativa robusta enquanto trabalha no scraper.
-   **Cuidado com o :** O ficheiro é um campo minado. Antes de adicionar qualquer nova rota, use  para se certificar de que não existe uma rota duplicada. A refatoração é crucial, mas só deve ser abordada após desbloquear a tarefa principal do utilizador.

**documents created in this job**
-   /app/GUIA_RELATORIOS_SINCRONIZACAO.md
-   /app/TUTORIAL_VIA_VERDE_PASSO_A_PASSO.md

**Last 10 User Messages and any pending user messages**
1.  **User**: Pede para implementar sincronização automática com várias plataformas. -> **Status**: INICIADO (criada página de gestão de credenciais).
2.  **User**: Reporta erro ao carregar credenciais. -> **Status**: CONCLUÍDO (bug de ObjectId e duplicados corrigido).
3.  **User**: Reporta erro ao criar novas credenciais. -> **Status**: CONCLUÍDO (bug de rota POST duplicada corrigido).
4.  **User**: Reporta Falha no login do scraper e pergunta o que fazer. -> **Status**: RESPONDIDO (agente explicou o estado e sugeriu fallback).
5.  **User**: Pede para focar na Via Verde e fornece credenciais. -> **Status**: EM ANDAMENTO.
6.  **User**: Pergunta sobre como programar a extração e envia screenshots do processo manual. -> **Status**: RESPONDIDO (agente analisou e ajustou o plano).
7.  **User**: Pede nova tentativa de login. -> **Status**: EM ANDAMENTO.
8.  **User**: Clarifica que a password não fica visível ao ser preenchida e envia screenshot. -> **Status**: INFORMAÇÃO CRÍTICA RECEBIDA.
9.  **User**: Pede simulação em vídeo. -> **Status**: CONCLUÍDO (agente usou a screenshot tool para simular).
10. **User**: Pede para avançar passo a passo e envia mais screenshots detalhados. -> **Status**: RESPONDIDO (agente analisou e criou um tutorial).

**Project Health Check:**
-   **Broken**: A funcionalidade de scraping automático, que é o foco atual, está quebrada. O login na Via Verde não funciona.
-   **Mocked**: O envio de relatórios por Email/WhatsApp; os parsers para os CSVs importados manualmente.

**3rd Party Integrations**
-   **Playwright**: Adicionada para web scraping.
-   **Moloni**: Integração existente, mas funcionalidade de faturação ainda por testar.

**Testing status**
-   Testing agent used after significant changes: NO
-   Troubleshoot agent used after agent stuck in loop: NO
-   Test files created: []
-   Known regressions: Nenhum identificado, mas o risco é elevado devido à dívida técnica no .

**Credentials to test flow:**
-   **Credenciais da Aplicação:** Disponíveis em .
-   **Credenciais da Via Verde (para scraping):**
    -   **Email:** 
    -   **Password:** 

**What agent forgot to execute**
-   Não removeu os ficheiros de frontend obsoletos (ex: ).
-   Não removeu o script de scraper obsoleto ().
-   Não implementou a lógica real nos parsers de CSV (), que continuam a ser placeholders.
-   A tarefa de refatoração do  continua pendente.</analysis>

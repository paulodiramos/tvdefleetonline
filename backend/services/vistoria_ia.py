"""
ServiÃ§o de AnÃ¡lise de Imagens com IA para Vistorias
- DeteÃ§Ã£o de danos
- OCR de matrÃ­cula
- ComparaÃ§Ã£o entre vistorias
"""

import os
import base64
import logging
from typing import Optional, List, Dict
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

# Emergent LLM Key
EMERGENT_LLM_KEY = os.environ.get("EMERGENT_LLM_KEY")


async def analisar_danos_imagem(image_base64: str, contexto: str = "") -> Dict:
    """
    Analisa uma imagem para detetar danos no veÃ­culo usando GPT-4 Vision
    """
    if not EMERGENT_LLM_KEY:
        logger.warning("EMERGENT_LLM_KEY nÃ£o configurada")
        return {"erro": "IA nÃ£o configurada", "danos": []}
    
    try:
        from emergentintegrations.llm.chat import LlmChat, UserMessage, ImageContent
        
        chat = LlmChat(
            api_key=EMERGENT_LLM_KEY,
            session_id=f"vistoria-analise-{id(image_base64)}",
            system_message="""VocÃª Ã© um especialista em inspeÃ§Ã£o de veÃ­culos. 
Analise a imagem do veÃ­culo e identifique TODOS os danos visÃ­veis.
Para cada dano encontrado, indique:
- Tipo: risco, amolgadela, vidro_partido, falta_peca, sujidade, ferrugem, pintura_danificada
- LocalizaÃ§Ã£o: descreva onde estÃ¡ no veÃ­culo
- Gravidade: leve, moderado, grave
- DescriÃ§Ã£o: breve descriÃ§Ã£o do dano

Responda APENAS em formato JSON assim:
{
  "danos_encontrados": [
    {"tipo": "...", "localizacao": "...", "gravidade": "...", "descricao": "..."}
  ],
  "estado_geral": "bom/razoavel/mau",
  "observacoes": "..."
}

Se nÃ£o houver danos visÃ­veis, retorne danos_encontrados como array vazio."""
        ).with_model("openai", "gpt-4o")
        
        image_content = ImageContent(image_base64=image_base64)
        
        prompt = f"Analise esta imagem do veÃ­culo e identifique todos os danos visÃ­veis."
        if contexto:
            prompt += f"\nContexto adicional: {contexto}"
        
        user_message = UserMessage(
            text=prompt,
            file_contents=[image_content]
        )
        
        response = await chat.send_message(user_message)
        
        # Tentar parsear JSON da resposta
        import json
        try:
            # Limpar resposta se necessÃ¡rio
            response_text = response.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            
            resultado = json.loads(response_text.strip())
            return resultado
        except json.JSONDecodeError:
            return {
                "danos_encontrados": [],
                "estado_geral": "indefinido",
                "observacoes": response,
                "parse_error": True
            }
            
    except Exception as e:
        logger.error(f"Erro na anÃ¡lise de danos: {e}")
        return {"erro": str(e), "danos_encontrados": []}


async def ler_matricula_imagem(image_base64: str) -> Dict:
    """
    Faz OCR da matrÃ­cula do veÃ­culo usando GPT-4 Vision
    """
    if not EMERGENT_LLM_KEY:
        return {"erro": "IA nÃ£o configurada", "matricula": None}
    
    try:
        from emergentintegrations.llm.chat import LlmChat, UserMessage, ImageContent
        
        chat = LlmChat(
            api_key=EMERGENT_LLM_KEY,
            session_id=f"vistoria-ocr-{id(image_base64)}",
            system_message="""VocÃª Ã© um sistema de OCR especializado em matrÃ­culas de veÃ­culos portugueses.
Analise a imagem e extraia a matrÃ­cula do veÃ­culo.
Responda APENAS com o JSON:
{
  "matricula": "XX-XX-XX",
  "confianca": "alta/media/baixa",
  "formato_valido": true/false
}
Se nÃ£o conseguir ler a matrÃ­cula, retorne matricula como null."""
        ).with_model("openai", "gpt-4o")
        
        image_content = ImageContent(image_base64=image_base64)
        
        user_message = UserMessage(
            text="Leia a matrÃ­cula do veÃ­culo nesta imagem.",
            file_contents=[image_content]
        )
        
        response = await chat.send_message(user_message)
        
        import json
        try:
            response_text = response.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            
            resultado = json.loads(response_text.strip())
            return resultado
        except json.JSONDecodeError:
            # Tentar extrair matrÃ­cula do texto
            import re
            match = re.search(r'[A-Z0-9]{2}[-\s]?[A-Z0-9]{2}[-\s]?[A-Z0-9]{2}', response.upper())
            if match:
                return {"matricula": match.group().replace(" ", "-"), "confianca": "baixa"}
            return {"matricula": None, "confianca": "nenhuma", "resposta_raw": response}
            
    except Exception as e:
        logger.error(f"Erro no OCR de matrÃ­cula: {e}")
        return {"erro": str(e), "matricula": None}


async def comparar_vistorias(vistoria_anterior: Dict, vistoria_atual: Dict) -> Dict:
    """
    Compara duas vistorias e identifica diferenÃ§as/novos danos
    """
    if not EMERGENT_LLM_KEY:
        return {"erro": "IA nÃ£o configurada"}
    
    try:
        from emergentintegrations.llm.chat import LlmChat, UserMessage
        
        chat = LlmChat(
            api_key=EMERGENT_LLM_KEY,
            session_id=f"vistoria-comparacao-{id(vistoria_atual)}",
            system_message="""VocÃª Ã© um especialista em anÃ¡lise de vistorias de veÃ­culos.
Compare duas vistorias e identifique:
1. Novos danos que nÃ£o existiam antes
2. Danos que pioraram
3. Danos que foram reparados
4. DiferenÃ§a de quilometragem
5. DiferenÃ§a de combustÃ­vel

Responda em JSON:
{
  "novos_danos": [...],
  "danos_agravados": [...],
  "danos_reparados": [...],
  "km_diferenca": 0,
  "combustivel_diferenca": 0,
  "resumo": "...",
  "alertas": [...]
}"""
        ).with_model("openai", "gpt-4o")
        
        user_message = UserMessage(
            text=f"""Compare estas duas vistorias:

VISTORIA ANTERIOR ({vistoria_anterior.get('data', 'N/A')}):
- KM: {vistoria_anterior.get('km', 'N/A')}
- CombustÃ­vel: {vistoria_anterior.get('nivel_combustivel', 'N/A')}%
- Danos: {vistoria_anterior.get('danos', [])}
- AnÃ¡lise IA: {vistoria_anterior.get('analise_ia', {})}

VISTORIA ATUAL ({vistoria_atual.get('data', 'N/A')}):
- KM: {vistoria_atual.get('km', 'N/A')}
- CombustÃ­vel: {vistoria_atual.get('nivel_combustivel', 'N/A')}%
- Danos: {vistoria_atual.get('danos', [])}
- AnÃ¡lise IA: {vistoria_atual.get('analise_ia', {})}

Identifique todas as diferenÃ§as relevantes."""
        )
        
        response = await chat.send_message(user_message)
        
        import json
        try:
            response_text = response.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            
            return json.loads(response_text.strip())
        except json.JSONDecodeError:
            return {"resumo": response, "parse_error": True}
            
    except Exception as e:
        logger.error(f"Erro na comparaÃ§Ã£o de vistorias: {e}")
        return {"erro": str(e)}


async def gerar_relatorio_vistoria(vistoria: Dict, comparacao: Optional[Dict] = None) -> str:
    """
    Gera um relatÃ³rio textual da vistoria para envio por WhatsApp/Email
    """
    if not EMERGENT_LLM_KEY:
        # Gerar relatÃ³rio bÃ¡sico sem IA
        return _gerar_relatorio_basico(vistoria, comparacao)
    
    try:
        from emergentintegrations.llm.chat import LlmChat, UserMessage
        
        chat = LlmChat(
            api_key=EMERGENT_LLM_KEY,
            session_id=f"vistoria-relatorio-{vistoria.get('id', '')}",
            system_message="""VocÃª gera relatÃ³rios de vistoria de veÃ­culos em portuguÃªs de Portugal.
O relatÃ³rio deve ser:
- Claro e profissional
- Formatado para WhatsApp (use emojis relevantes)
- Incluir link de confirmaÃ§Ã£o no final
- MÃ¡ximo 1500 caracteres"""
        ).with_model("openai", "gpt-4o")
        
        dados = f"""
Tipo: {vistoria.get('tipo', 'N/A')}
Data: {vistoria.get('data', 'N/A')}
VeÃ­culo: {vistoria.get('veiculo_matricula', 'N/A')}
Motorista: {vistoria.get('motorista_nome', 'N/A')}
KM: {vistoria.get('km', 'N/A')}
CombustÃ­vel: {vistoria.get('nivel_combustivel', 'N/A')}%
Danos marcados: {len(vistoria.get('danos', []))}
ObservaÃ§Ãµes: {vistoria.get('observacoes', 'Nenhuma')}
"""
        if comparacao:
            dados += f"\nComparaÃ§Ã£o com vistoria anterior: {comparacao.get('resumo', 'N/A')}"
        
        user_message = UserMessage(
            text=f"Gera um relatÃ³rio de vistoria para WhatsApp com estes dados:\n{dados}\n\nLink de confirmaÃ§Ã£o: [LINK_CONFIRMACAO]"
        )
        
        response = await chat.send_message(user_message)
        return response
        
    except Exception as e:
        logger.error(f"Erro ao gerar relatÃ³rio: {e}")
        return _gerar_relatorio_basico(vistoria, comparacao)


def _gerar_relatorio_basico(vistoria: Dict, comparacao: Optional[Dict] = None) -> str:
    """Gera relatÃ³rio bÃ¡sico sem IA"""
    tipo_emoji = "ğŸ“¥" if vistoria.get('tipo') == 'entrada' else "ğŸ“¤"
    
    relatorio = f"""
{tipo_emoji} *RELATÃ“RIO DE VISTORIA*

ğŸ“… Data: {vistoria.get('data', 'N/A')}
ğŸš— VeÃ­culo: {vistoria.get('veiculo_matricula', 'N/A')}
ğŸ‘¤ Motorista: {vistoria.get('motorista_nome', 'N/A')}

ğŸ“Š *Dados do VeÃ­culo:*
â€¢ Quilometragem: {vistoria.get('km', 'N/A')} km
â€¢ CombustÃ­vel: {vistoria.get('nivel_combustivel', 'N/A')}%

"""
    
    danos = vistoria.get('danos', [])
    if danos:
        relatorio += f"âš ï¸ *Danos Registados ({len(danos)}):*\n"
        for i, dano in enumerate(danos, 1):
            relatorio += f"  {i}. {dano.get('tipo', 'N/A')}\n"
    else:
        relatorio += "âœ… *Sem danos registados*\n"
    
    if vistoria.get('observacoes'):
        relatorio += f"\nğŸ“ *ObservaÃ§Ãµes:*\n{vistoria.get('observacoes')}\n"
    
    if comparacao and not comparacao.get('erro'):
        relatorio += f"\nğŸ”„ *ComparaÃ§Ã£o:*\n{comparacao.get('resumo', 'N/A')}\n"
    
    relatorio += "\n---\nğŸ”— Para confirmar esta vistoria, clique no link:\n[LINK_CONFIRMACAO]"
    
    return relatorio
